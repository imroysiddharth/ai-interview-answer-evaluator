# ğŸ™ï¸ AI Interview Answer Evaluator

An **AI-powered interview evaluation system** that analyzes spoken interview answers and produces **structured feedback and scores** based on clarity, relevance, and confidence.

The project is **automation-first**, has **minimal UI**, and is designed for **real-world usage** by recruiters, candidates, and interview coaching platforms.

---

## ğŸš€ Features

* ğŸ§ Upload interview answers as audio (`.wav`, `.mp3`, `.m4a`)
* ğŸ§  Speech-to-text using **Whisper (faster-whisper)**
* ğŸ“Š LLM-based evaluation using **Google Gemini** (OpenAI optional)
* âœ… Scores for:

  * Clarity
  * Relevance
  * Confidence
  * Overall Score
* ğŸ“ Actionable strengths & improvement suggestions
* ğŸ”Œ Clean REST API built with **FastAPI**
* ğŸ¨ Lightweight **Streamlit UI** (frontend only, backend unchanged)
* ğŸ³ Fully **Dockerized** (backend + UI)

---

## ğŸ—ï¸ Architecture Overview

```
Audio Input
    â†“
Speech-to-Text (Whisper)
    â†“
Text Cleaning & Normalization
    â†“
LLM Evaluation (Gemini / OpenAI)
    â†“
Scoring Engine
    â†“
JSON Feedback (FastAPI API)
    â†“
Streamlit UI (Optional)
```

---

## ğŸ›  Tech Stack

### Backend

* Python
* FastAPI
* Whisper (faster-whisper)
* Google Gemini (LLM)
* Optional: OpenAI (fallback)

### Frontend

* Streamlit

### Dev & Infra

* Docker & Docker Compose
* FFmpeg
* Uvicorn
* Watchdog

---

## ğŸ“‚ Project Structure

```
ai-interview-answer-evaluator/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ whisper_service.py
â”‚   â”œâ”€â”€ evaluator/
â”‚   â”‚   â”œâ”€â”€ gemini_evaluator.py
â”‚   â”‚   â”œâ”€â”€ openai_evaluator.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ UI/
â”‚       â””â”€â”€ ui.py
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Dockerfile.ui
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ sample_audio/
```

---

## âš™ï¸ Local Setup (Without Docker)

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/siddharthk2608/ai-interview-answer-evaluator.git
cd ai-interview-answer-evaluator
```

### 2ï¸âƒ£ Create & Activate Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Install FFmpeg

```bash
brew install ffmpeg   # macOS
sudo apt install ffmpeg  # Linux
```

### 5ï¸âƒ£ Set Environment Variables

```bash
export GOOGLE_API_KEY="your_gemini_api_key"
```

---

## â–¶ï¸ Run the Backend API

```bash
uvicorn app.main:app --reload
```

Swagger UI:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ¨ Run the Streamlit UI (Local)

```bash
streamlit run app/UI/ui.py
```

---

## ğŸ³ Run with Docker (Recommended)

### Build & Run

```bash
docker-compose up --build
```

### Access

* Backend API â†’ [http://localhost:8000/docs](http://localhost:8000/docs)
* Streamlit UI â†’ [http://localhost:8501](http://localhost:8501)

### Stop Containers

```bash
docker-compose down
```

---

## ğŸ“¤ API Usage Example

```bash
curl -X POST "http://127.0.0.1:8000/evaluate?question=Tell%20me%20about%20a%20challenging%20project" \
  -F "audio=@answer.wav"
```

---

## ğŸ“Œ Resume Bullet Points

* Built an **AI-powered interview evaluation platform** using Whisper and LLMs to score spoken answers on clarity, relevance, and confidence
* Designed a **FastAPI-based scoring engine** with clean REST endpoints and JSON feedback
* Implemented a **Dockerized microservice architecture** with Streamlit UI and FastAPI backend
* Integrated **Google Gemini** for automated qualitative assessment of interview responses

---

## ğŸ”’ Notes

* API keys are managed via environment variables
* `.env`, virtual environments, and large media files are excluded via `.gitignore` and `.dockerignore`

---
